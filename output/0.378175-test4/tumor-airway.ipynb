{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Huangkuanrong/LungsTumorDetection/blob/master/codes/1.%20Yolo-V5%20BCC%20Training%20%26%20Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Extraction of data labels from .xml file to dataframe","metadata":{"id":"iccVsnt7VJk1"}},{"cell_type":"code","source":"import wandb\nwandb.init(project=\"test-project\", entity=\"alex-and-jason\")","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:15:03.749813Z","iopub.execute_input":"2022-05-17T03:15:03.750468Z","iopub.status.idle":"2022-05-17T03:15:30.344035Z","shell.execute_reply.started":"2022-05-17T03:15:03.750426Z","shell.execute_reply":"2022-05-17T03:15:30.343246Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import shutil\nimport os, sys, random\nimport xml.etree.ElementTree as ET\nfrom glob import glob\nimport pandas as pd\nfrom shutil import copyfile\nimport pandas as pd\nfrom sklearn import preprocessing, model_selection\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import patches\nimport numpy as np\nimport os","metadata":{"id":"Qj5wjt0-fRbS","tags":[],"execution":{"iopub.status.busy":"2022-05-17T03:15:57.703894Z","iopub.execute_input":"2022-05-17T03:15:57.704168Z","iopub.status.idle":"2022-05-17T03:15:58.390151Z","shell.execute_reply.started":"2022-05-17T03:15:57.704134Z","shell.execute_reply":"2022-05-17T03:15:58.389373Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"/kaggle/working/content\")","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:16:01.526080Z","iopub.execute_input":"2022-05-17T03:16:01.526330Z","iopub.status.idle":"2022-05-17T03:16:01.536761Z","shell.execute_reply.started":"2022-05-17T03:16:01.526302Z","shell.execute_reply":"2022-05-17T03:16:01.533913Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"/kaggle/working/content\")","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:16:04.605335Z","iopub.execute_input":"2022-05-17T03:16:04.605619Z","iopub.status.idle":"2022-05-17T03:16:04.615078Z","shell.execute_reply.started":"2022-05-17T03:16:04.605588Z","shell.execute_reply":"2022-05-17T03:16:04.611230Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!git clone 'https://Huangkuanrong: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@github.com/Huangkuanrong/LungsTumorDetection.git'","metadata":{"id":"hVcWncA_iJR9","outputId":"d7c22de2-daed-42b1-a995-e07507d77c94","tags":[],"execution":{"iopub.status.busy":"2022-05-17T03:16:06.736994Z","iopub.execute_input":"2022-05-17T03:16:06.737604Z","iopub.status.idle":"2022-05-17T03:16:23.654801Z","shell.execute_reply.started":"2022-05-17T03:16:06.737560Z","shell.execute_reply":"2022-05-17T03:16:23.653717Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"annotations = sorted(glob('LungsTumorDetection/dataset/Train_Annotations/*.xml'))\n\ndf = []\ncnt = 0\nfor file in annotations:\n  prev_filename = file.split('/')[-1].split('.')[0] + '.jpg'\n  filename = str(cnt) + '.jpg'\n  row = []\n  parsedXML = ET.parse(file)\n  for node in parsedXML.getroot().iter('object'):\n    if node.find('name').text == \"STAS\" : blood_cells = \"stas\"\n    else : blood_cells = node.find('name').text\n    xmin = int(node.find('bndbox/xmin').text)\n    xmax = int(node.find('bndbox/xmax').text)\n    ymin = int(node.find('bndbox/ymin').text)\n    ymax = int(node.find('bndbox/ymax').text)\n\n    row = [prev_filename, filename, blood_cells, xmin, xmax, ymin, ymax]\n    df.append(row)\n  cnt += 1\n\ndata = pd.DataFrame(df, columns=['prev_filename', 'filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax'])\n\ndata[['prev_filename','filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax']].to_csv('LungsTumorDetection/blood_cell_detection.csv', index=False)\n","metadata":{"id":"4_8R_DIIiQEY","execution":{"iopub.status.busy":"2022-05-17T03:16:26.541190Z","iopub.execute_input":"2022-05-17T03:16:26.541845Z","iopub.status.idle":"2022-05-17T03:16:26.710946Z","shell.execute_reply.started":"2022-05-17T03:16:26.541802Z","shell.execute_reply":"2022-05-17T03:16:26.710222Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Processing data as per the YOLO_V5 format","metadata":{"id":"_6cRsoE6VRAD"}},{"cell_type":"markdown","source":"**DATAFRAME STRUCTURE**\n\n- filename : contains the name of the image\n- cell_type: denotes the type of the cell\n- xmin: x-coordinate of the bottom left part of the image\n- xmax: x-coordinate of the top right part of the image\n- ymin: y-coordinate of the bottom left part of the image\n- ymax: y-coordinate of the top right part of the image\n- labels : Encoded cell-type **(Yolo - label input-1)**\n- width : width of that bbox\n- height : height of that bbox\n- x_center : bbox center (x-axis)\n-\ty_center : bbox center (y-axis)\n-\tx_center_norm\t: x_center normalized (0-1) **(Yolo - label input-2)**\n-\ty_center_norm : y_center normalized (0-1) **(Yolo - label input-3)**\n- width_norm : width normalized (0-1) **(Yolo - label input-4)**\n-\theight_norm : height normalized (0-1) **(Yolo - label input-5)**","metadata":{"id":"Onr1Vqm4x4qz"}},{"cell_type":"code","source":"img_width = 1716\nimg_height = 942\n\ndef width(df):\n  return int(df.xmax - df.xmin)\ndef height(df):\n  return int(df.ymax - df.ymin)\ndef x_center(df):\n  return int(df.xmin + (df.width/2))\ndef y_center(df):\n  return int(df.ymin + (df.height/2))\ndef w_norm(df):\n  return df/img_width\ndef h_norm(df):\n  return df/img_height\n\ndf = pd.read_csv('LungsTumorDetection/blood_cell_detection.csv')\n\nle = preprocessing.LabelEncoder()\nle.fit(df['cell_type'])\nprint(le.classes_)\nlabels = le.transform(df['cell_type'])\ndf['labels'] = labels\n\ndf['width'] = df.apply(width, axis=1)\ndf['height'] = df.apply(height, axis=1)\n\ndf['x_center'] = df.apply(x_center, axis=1)\ndf['y_center'] = df.apply(y_center, axis=1)\n\ndf['x_center_norm'] = df['x_center'].apply(w_norm)\ndf['width_norm'] = df['width'].apply(w_norm)\n\ndf['y_center_norm'] = df['y_center'].apply(h_norm)\ndf['height_norm'] = df['height'].apply(h_norm)\n\ndf.head(30)","metadata":{"id":"2rybfBj3mwBV","outputId":"df4882d7-af7a-4d8b-9a2a-d3499a237712","execution":{"iopub.status.busy":"2022-05-17T03:16:31.193363Z","iopub.execute_input":"2022-05-17T03:16:31.194312Z","iopub.status.idle":"2022-05-17T03:16:31.581105Z","shell.execute_reply.started":"2022-05-17T03:16:31.194264Z","shell.execute_reply":"2022-05-17T03:16:31.580397Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#@title SAMPLE PLOT - shape (480, 640, 3)\nfig = plt.figure()\nimport cv2\n#add axes to the image\nax = fig.add_axes([0,0,1,1])\n\n# read and plot the image\nimage = plt.imread('LungsTumorDetection/dataset/Train_Images/00000000.jpg')\nplt.imshow(image)\n\n# iterating over the image for different objects\nfor _,row in df[df.filename == \"1.jpg\"].iterrows():\n    xmin = row.xmin\n    xmax = row.xmax\n    ymin = row.ymin\n    ymax = row.ymax\n    \n    width = xmax - xmin\n    height = ymax - ymin\n    \n    # assign different color to different classes of objects\n    if row.cell_type == 'stas':\n        edgecolor = 'r'\n        ax.annotate('stas', xy=(xmax-40,ymin+20))\n        \n    # add bounding boxes to the image\n    rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = 'none')\n    \n    ax.add_patch(rect)","metadata":{"id":"pk4xn6BJ4B6q","outputId":"f0c17dec-2650-48ed-f5e1-585d78fa16b9"}},{"cell_type":"markdown","source":"# Splitting into training and validation datasets","metadata":{"id":"CLnE5tWOVaKM"}},{"cell_type":"code","source":"df_train, df_valid = model_selection.train_test_split(df, test_size=0.3, random_state=13, shuffle=True)\nprint(df_train.shape, df_valid.shape)","metadata":{"id":"gRrIQI7m8H5P","outputId":"6d10fb47-aaf9-408f-aea9-020602928dae","execution":{"iopub.status.busy":"2022-05-17T03:16:39.326936Z","iopub.execute_input":"2022-05-17T03:16:39.327481Z","iopub.status.idle":"2022-05-17T03:16:39.342990Z","shell.execute_reply.started":"2022-05-17T03:16:39.327440Z","shell.execute_reply":"2022-05-17T03:16:39.342047Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree(\"LungsTumorDetection/bcc/\")","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:16:41.602352Z","iopub.execute_input":"2022-05-17T03:16:41.603162Z","iopub.status.idle":"2022-05-17T03:16:41.721412Z","shell.execute_reply.started":"2022-05-17T03:16:41.603113Z","shell.execute_reply":"2022-05-17T03:16:41.720675Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"os.mkdir('LungsTumorDetection/bcc/')\nos.mkdir('LungsTumorDetection/bcc/images/')\nos.mkdir('LungsTumorDetection/bcc/images/train/')\nos.mkdir('LungsTumorDetection/bcc/images/valid/')\n\nos.mkdir('LungsTumorDetection/bcc/labels/')\nos.mkdir('LungsTumorDetection/bcc/labels/train/')\nos.mkdir('LungsTumorDetection/bcc/labels/valid/')","metadata":{"id":"zO6iT6rQ-2f3","execution":{"iopub.status.busy":"2022-05-17T03:16:44.787468Z","iopub.execute_input":"2022-05-17T03:16:44.788021Z","iopub.status.idle":"2022-05-17T03:16:44.800861Z","shell.execute_reply.started":"2022-05-17T03:16:44.787979Z","shell.execute_reply":"2022-05-17T03:16:44.799697Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Data segregation and moving to it's corresponding folders\n- BCC\n  - Images\n    - Train (364 images [.jpg files])\n    - Valid (270 images [.jpg files])\n  - Labels\n    - Train (364 labels [.txt files])\n    - Valid (270 labels [.txt files])\n","metadata":{"id":"bmsqg2dYACVr"}},{"cell_type":"markdown","source":"**STRUCTURE OF .txt FILE**\n\n- One row per object\n- Each row is class x_center y_center width height format.\n- Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes  are in pixels, divide x_center and width by image width, and y_center and height by image height.\n- Class numbers are zero-indexed (start from 0).\n","metadata":{"id":"2IACNN0QxC4s"}},{"cell_type":"markdown","source":"<img src=\"https://github.com/bala-codes/Yolo-v5_Object_Detection_Blood_Cell_Count_and_Detection/blob/master/imgs/label_txt.PNG?raw=true\" width=\"50%\">\n","metadata":{"id":"_VgUi-pQ0BZo"}},{"cell_type":"code","source":"def segregate_data(df, img_path, label_path, train_img_path, train_label_path):\n  filenames = []\n  for filename in df.filename:\n    filenames.append(filename)\n  filenames = set(filenames)\n  \n  for filename in filenames:\n    yolo_list = []\n\n    for _,row in df[df.filename == filename].iterrows():\n      yolo_list.append([row.labels, row.x_center_norm, row.y_center_norm, row.width_norm, row.height_norm])\n\n    yolo_list = np.array(yolo_list)\n    txt_filename = os.path.join(train_label_path,str(row.prev_filename.split('.')[0])+\".txt\")\n    # Save the .img & .txt files to the corresponding train and validation folders\n    np.savetxt(txt_filename, yolo_list, fmt=[\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"])\n    shutil.copyfile(os.path.join(img_path,row.prev_filename), os.path.join(train_img_path,row.prev_filename))","metadata":{"id":"Bo21M14uF25h","execution":{"iopub.status.busy":"2022-05-17T03:16:49.351134Z","iopub.execute_input":"2022-05-17T03:16:49.351401Z","iopub.status.idle":"2022-05-17T03:16:49.359400Z","shell.execute_reply.started":"2022-05-17T03:16:49.351367Z","shell.execute_reply":"2022-05-17T03:16:49.358724Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"%%time\nsrc_img_path = \"LungsTumorDetection/dataset/Train_Images/\"\nsrc_label_path = \"LungsTumorDetection/dataset/Train_Annotations/\"\n\ntrain_img_path = \"LungsTumorDetection/bcc/images/train\"\ntrain_label_path = \"LungsTumorDetection/bcc/labels/train\"\n\nvalid_img_path = \"LungsTumorDetection/bcc/images/valid\"\nvalid_label_path = \"LungsTumorDetection/bcc/labels/valid\"\n\nsegregate_data(df_train, src_img_path, src_label_path, train_img_path, train_label_path)\nsegregate_data(df_valid, src_img_path, src_label_path, valid_img_path, valid_label_path)","metadata":{"id":"4uy4rLGYSBd7","outputId":"fc4d922a-416c-4d25-8a7d-89224f388fe1","execution":{"iopub.status.busy":"2022-05-17T03:16:51.766944Z","iopub.execute_input":"2022-05-17T03:16:51.767659Z","iopub.status.idle":"2022-05-17T03:16:54.228613Z","shell.execute_reply.started":"2022-05-17T03:16:51.767618Z","shell.execute_reply":"2022-05-17T03:16:54.227883Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"try:\n  shutil.rmtree('LungsTumorDetection/bcc/images/train/.ipynb_checkpoints')\nexcept FileNotFoundError:\n  pass\n\ntry:\n  shutil.rmtree('LungsTumorDetection/bcc/images/valid/.ipynb_checkpoints')\nexcept FileNotFoundError:\n  pass\n\ntry:\n  shutil.rmtree('LungsTumorDetection/bcc/labels/train/.ipynb_checkpoints')\nexcept FileNotFoundError:\n  pass\n\ntry:\n  shutil.rmtree('LungsTumorDetection/bcc/labels/valid/.ipynb_checkpoints')\nexcept FileNotFoundError:\n  pass\n\nprint(\"No. of Training images\", len(os.listdir('LungsTumorDetection/bcc/images/train')))\nprint(\"No. of Training labels\", len(os.listdir('LungsTumorDetection/bcc/labels/train')))\n\nprint(\"No. of valid images\", len(os.listdir('LungsTumorDetection/bcc/images/valid')))\nprint(\"No. of valid labels\", len(os.listdir('LungsTumorDetection/bcc/labels/valid')))","metadata":{"id":"LDv31-CdS_nt","outputId":"3720e8cd-57d9-47a4-b3dc-197fd274f9e6","execution":{"iopub.status.busy":"2022-05-17T03:16:54.230558Z","iopub.execute_input":"2022-05-17T03:16:54.231058Z","iopub.status.idle":"2022-05-17T03:16:54.243015Z","shell.execute_reply.started":"2022-05-17T03:16:54.231017Z","shell.execute_reply":"2022-05-17T03:16:54.242201Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# **END OF DATA PRE-PROCESSING**","metadata":{"id":"V2uPhrQCU6vT"}},{"cell_type":"markdown","source":"#**YOLO V5 STARTS**","metadata":{"id":"gjHmEIfmWNms"}},{"cell_type":"markdown","source":"!mkdir -p '/content/drive/My Drive/Machine Learning Projects/YOLO/'\n!cp -r '/content/bcc' '/content/drive/My Drive/Machine Learning Projects/YOLO/'","metadata":{"id":"05kiA297y2s3"}},{"cell_type":"markdown","source":"# Cloning from the yolo v5 repo.\nMore can be found at here : [yolo](https://github.com/ultralytics/yolov5)","metadata":{"id":"lcA59GtHeCrd"}},{"cell_type":"markdown","source":"!git clone  'https://github.com/ultralytics/yolov5.git'","metadata":{"id":"YnhcNiuTGAK7","outputId":"48065640-6b1f-4fdc-e870-73b352fea8e9"}},{"cell_type":"markdown","source":"!pip install -r 'yolov5/requirements.txt'  # install dependencies","metadata":{"id":"A4i0BpZIbyTz","outputId":"fb23dff3-8223-4cb7-943f-abe57ff96f3b","tags":[]}},{"cell_type":"markdown","source":"# WE SHOULD CREATE A .yaml FILE AND THEN PLACE IT INSIDE THE yolov5 FOLDER","metadata":{"id":"KUsMKPtGeUcv"}},{"cell_type":"markdown","source":"#**Contents of YAML file**\n\ntrain: /content/bcc/images/train                    \nval: /content/bcc/images/valid\n\nnc: 3\n\nnames: ['Platelets', 'RBC', 'WBC']\n","metadata":{"id":"bqymagYif3Us"}},{"cell_type":"code","source":"!echo -e 'train: ../bcc/images/train\\nval: ../bcc/images/valid\\n\\nnc: 1\\nnames: ['stas']' >> bcc.yaml\n!cat 'bcc.yaml'","metadata":{"id":"IgIO3balXB-B","outputId":"e6b73b9f-64c0-4f08-e6a9-98b5e7d63f9b","execution":{"iopub.status.busy":"2022-05-17T03:17:44.540829Z","iopub.execute_input":"2022-05-17T03:17:44.541099Z","iopub.status.idle":"2022-05-17T03:17:45.855884Z","shell.execute_reply.started":"2022-05-17T03:17:44.541067Z","shell.execute_reply":"2022-05-17T03:17:45.855040Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"shutil.copyfile('bcc.yaml', 'LungsTumorDetection/bcc.yaml')","metadata":{"id":"31-z05sIcMcv","outputId":"9aa74848-a313-43bd-e9db-f9a9dc34a750","execution":{"iopub.status.busy":"2022-05-17T03:17:50.452217Z","iopub.execute_input":"2022-05-17T03:17:50.452500Z","iopub.status.idle":"2022-05-17T03:17:50.461437Z","shell.execute_reply.started":"2022-05-17T03:17:50.452469Z","shell.execute_reply":"2022-05-17T03:17:50.460644Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"#**Also edit the number of classes (nc) in the ./models/*.yaml file**\n\nChoose the yolo model of your choice, here I chose yolov5s.yaml (yolo - small)\n","metadata":{"id":"7gUcPKfsDlEQ"}},{"cell_type":"code","source":"!sed -i 's/nc: 80/nc: 1/g' ./LungsTumorDetection/yolov5/models/yolov5m.yaml","metadata":{"id":"0cXuPZjRhg3o","execution":{"iopub.status.busy":"2022-05-17T03:18:00.222449Z","iopub.execute_input":"2022-05-17T03:18:00.223250Z","iopub.status.idle":"2022-05-17T03:18:00.927128Z","shell.execute_reply.started":"2022-05-17T03:18:00.223201Z","shell.execute_reply":"2022-05-17T03:18:00.926012Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"wandb.config = {\n  \"learning_rate\": 0.01,\n  \"epochs\": 100,\n  \"batch_size\": 16\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:28:48.841260Z","iopub.execute_input":"2022-05-17T03:28:48.841548Z","iopub.status.idle":"2022-05-17T03:28:48.848376Z","shell.execute_reply.started":"2022-05-17T03:28:48.841502Z","shell.execute_reply":"2022-05-17T03:28:48.847484Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Training command","metadata":{"id":"g_4-F3I2gVIN"}},{"cell_type":"markdown","source":"**Training Parameters**\n\n!python \n- <'location of train.py file'> \n- --img <'width of image'>\n- --batch <'batch size'>\n- --epochs <'no of epochs'>\n- --data <'location of the .yaml file'>\n- --cfg <'Which yolo configuration you want'>(yolov5s/yolov5m/yolov5l/yolov5x).yaml | (small, medium, large, xlarge)\n- --name <'Name of the best model after training'>","metadata":{"id":"127Pw1oS1zzY"}},{"cell_type":"markdown","source":"**METRICS FROM TRAINING PROCESS**\n\n**No.of classes, No.of images, No.of targets, Precision (P), Recall (R), mean Average Precision (map)**\n- Class | Images | Targets | P | R | mAP@.5 | mAP@.5:.95: |\n- all   | 270    |     489 |    0.0899 |       0.827 |      0.0879 |      0.0551","metadata":{"id":"Ztjc7_wS5z2J"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"Q_zEQzDtpX1S","outputId":"80ec86cd-a1c1-48b6-f216-5ba67ec9aee0","tags":[],"execution":{"iopub.status.busy":"2022-05-17T03:18:07.200617Z","iopub.execute_input":"2022-05-17T03:18:07.201126Z","iopub.status.idle":"2022-05-17T03:18:07.907172Z","shell.execute_reply.started":"2022-05-17T03:18:07.201082Z","shell.execute_reply":"2022-05-17T03:18:07.906316Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"LungsTumorDetection/yolov5/\")","metadata":{"execution":{"iopub.status.busy":"2022-05-17T03:28:54.726220Z","iopub.execute_input":"2022-05-17T03:28:54.726491Z","iopub.status.idle":"2022-05-17T03:28:54.733390Z","shell.execute_reply.started":"2022-05-17T03:28:54.726449Z","shell.execute_reply":"2022-05-17T03:28:54.732583Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"%%time\n\n!python train.py --img 640 --batch 40 --epochs 100 --hyp data/hyps/hyp.scratch-med.yaml --data ../bcc.yaml --cfg models/yolov5m.yaml --name BCCM","metadata":{"id":"k3Tc61Qzd4lY","outputId":"7f0a0ebb-5799-456b-b671-d357efd5d679","tags":[],"execution":{"iopub.status.busy":"2022-05-17T03:31:18.298482Z","iopub.execute_input":"2022-05-17T03:31:18.299183Z","iopub.status.idle":"2022-05-17T06:37:52.508933Z","shell.execute_reply.started":"2022-05-17T03:31:18.299133Z","shell.execute_reply":"2022-05-17T06:37:52.508096Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"#**INFERENCE**","metadata":{"id":"DJYN1lb_uV-T"}},{"cell_type":"code","source":"#Optimizer stripped from runs/exp2_BCCM/weights/last_BCCM.pt, 14.8MB\n#Optimizer stripped from runs/exp2_BCCM/weights/best_BCCM.pt, 14.8MB","metadata":{"id":"FHnXEx4subZ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BATCH PREDICTION\n- Results saved to inference/output\n","metadata":{"id":"obKZFwYHvg6a"}},{"cell_type":"markdown","source":"**Inference Parameters**\n\n!python \n- <'location of detect.py file'> \n- --source <'location of image/ folder to predict'>\n- --weight <'location of the saved best weights'>\n- --output <'location of output files after prediction'>","metadata":{"id":"jtCUnoyr7h8y"}},{"cell_type":"markdown","source":"!python yolov5/detect.py --source /content/bcc/images/valid/ --weights '/content/runs/exp0_BCCM/weights/best.pt' --output '/content/inference/output'","metadata":{"id":"PoDLzE4xu_Bo","outputId":"b0e3e328-1fa1-480f-a7d9-73d9dd2b20ab"}},{"cell_type":"markdown","source":"disp_images = glob('/content/inference/output/*')\nfig=plt.figure(figsize=(20, 28))\ncolumns = 3\nrows = 5\nfor i in range(1, columns*rows +1):\n    img = np.random.choice(disp_images)\n    img = plt.imread(img)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","metadata":{"id":"1UFERGRGwOEQ","outputId":"cd0ebebc-ac6a-4b27-e681-58d91fe85362"}},{"cell_type":"markdown","source":"# IMAGE PREDICTIONS\n","metadata":{"id":"wrXZ10ikvnDB"}},{"cell_type":"markdown","source":"output = !python yolov5/detect.py --source /content/bcc/images/valid/BloodImage_00000.jpg --weights '/content/runs/exp0_BCCM/weights/best_BCCM.pt'\nprint(output)","metadata":{"id":"RuIiMYKdvRi1"}},{"cell_type":"code","source":"import cv2\nimport torch\nfrom PIL import Image\nimport json\n\ndef get_filename(im):\n  a = im.filename\n  b = a.split('/')[7]\n  return b\n\n# Model\nmodel = torch.hub.load('ultralytics/yolov5', 'custom', path='/kaggle/working/content/LungsTumorDetection/yolov5/runs/train/BCCM2/weights/best.pt')  # local model\ndict_x = {}\n\n# Images\nfor im_list in list(glob('/kaggle/working/content/LungsTumorDetection/dataset/Public_Image/*.jpg')):\n  im = Image.open(im_list)  # PIL image\n  # Inference\n  results = model(im, size=1920)  # includes NMS\n\n# # Results\n# results.print()  \n# results.save()  # or .show()\n# results.xyxy[0]  # im1 predictions (tensor)\n# print(results.pandas().xyxy[0].shape)  # im1 predictions (pandas)\n\n  list_x = []\n  signal = 0\n  for i in results.pandas().xyxy[0].values:\n    if (i[4]>=0.05): \n      temp_value = float(\"{0:.5f}\".format(i[4]))\n      templist_x=[int(j) for j in i[0:4]]\n      templist_x.append(temp_value)\n      list_x.append(templist_x)\n  dict_x.update({get_filename(im):list_x})\n\nprint(dict_x)\nprint(len(dict_x))\nwith open('/kaggle/working/result.json', 'w', encoding='utf-8') as f:\n    json.dump(dict_x, f, ensure_ascii=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T07:00:59.419097Z","iopub.execute_input":"2022-05-17T07:00:59.419369Z","iopub.status.idle":"2022-05-17T07:01:14.009751Z","shell.execute_reply.started":"2022-05-17T07:00:59.419340Z","shell.execute_reply":"2022-05-17T07:01:14.009007Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Download outputs : best.pt and result.json","metadata":{}},{"cell_type":"code","source":"from IPython.display import FileLink\n!zip -r /kaggle/working/best.zip /kaggle/working/content/LungsTumorDetection/yolov5/runs/train/BCCM2/weights/best.pt","metadata":{"execution":{"iopub.status.busy":"2022-05-17T07:03:18.370882Z","iopub.execute_input":"2022-05-17T07:03:18.371166Z","iopub.status.idle":"2022-05-17T07:03:21.295779Z","shell.execute_reply.started":"2022-05-17T07:03:18.371135Z","shell.execute_reply":"2022-05-17T07:03:21.295013Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('/kaggle/working/result.json')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T22:52:10.887014Z","iopub.execute_input":"2022-05-14T22:52:10.887295Z","iopub.status.idle":"2022-05-14T22:52:10.89429Z","shell.execute_reply.started":"2022-05-14T22:52:10.887264Z","shell.execute_reply":"2022-05-14T22:52:10.893571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n#!zip -r /kaggle/working/training.zip /kaggle/working/content/LungsTumorDetection/yolov5/runs/train/BCCM22\nFileLink(r'/kaggle/working/training.zip')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T23:04:35.96512Z","iopub.execute_input":"2022-05-14T23:04:35.965387Z","iopub.status.idle":"2022-05-14T23:04:35.974697Z","shell.execute_reply.started":"2022-05-14T23:04:35.965359Z","shell.execute_reply":"2022-05-14T23:04:35.973848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# You need these files, if you wish to move the model to production","metadata":{"id":"-1ZarG561ak5"}},{"cell_type":"markdown","source":"## Files","metadata":{"id":"AxI5iupx_jd1"}},{"cell_type":"markdown","source":"shutil.copyfile('/content/yolov5/detect.py', '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/detect.py')\nshutil.copyfile('/content/yolov5/requirements.txt', '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/requirements.txt')\nshutil.copyfile('/content/runs/exp2_BCCM/weights/best_BCCM.pt', '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/best_BCCM.pt')\n\n","metadata":{"id":"NSAegF-48fHj"}},{"cell_type":"markdown","source":"## Folder","metadata":{"id":"Kd-aarpL_lB1"}},{"cell_type":"markdown","source":"!cp -r '/content/yolov5/models' '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/'\n!cp -r '/content/yolov5/utils' '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/'\n","metadata":{"id":"I1Gup2m3vv_M"}}]}