{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Huangkuanrong/LungsTumorDetection/blob/master/codes/1.%20Yolo-V5%20BCC%20Training%20%26%20Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"os.mkdir(\"/content\")\nos.chdir(\"/content\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone 'https://Huangkuanrong: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@github.com/Huangkuanrong/LungsTumorDetection.git'","metadata":{"id":"hVcWncA_iJR9","outputId":"8142f838-a542-4a4a-8a70-7d2283921897","execution":{"iopub.status.busy":"2022-05-14T11:50:38.084235Z","iopub.execute_input":"2022-05-14T11:50:38.084842Z","iopub.status.idle":"2022-05-14T11:51:13.045780Z","shell.execute_reply.started":"2022-05-14T11:50:38.084795Z","shell.execute_reply":"2022-05-14T11:51:13.044952Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#**DATA PRE-PROCESSING STARTS**","metadata":{"id":"H4e9h0HfVA30"}},{"cell_type":"markdown","source":"# Extraction of data labels from .xml file to dataframe","metadata":{"id":"iccVsnt7VJk1"}},{"cell_type":"code","source":"import shutil\nimport os, sys, random\nimport xml.etree.ElementTree as ET\nfrom glob import glob\nimport pandas as pd\nfrom shutil import copyfile\nimport pandas as pd\nfrom sklearn import preprocessing, model_selection\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import patches\nimport numpy as np\nimport os\nimport shutil\n","metadata":{"id":"Qj5wjt0-fRbS","execution":{"iopub.status.busy":"2022-05-14T11:50:17.167120Z","iopub.execute_input":"2022-05-14T11:50:17.167538Z","iopub.status.idle":"2022-05-14T11:50:18.378670Z","shell.execute_reply.started":"2022-05-14T11:50:17.167501Z","shell.execute_reply":"2022-05-14T11:50:18.377749Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-14T11:50:27.775082Z","iopub.execute_input":"2022-05-14T11:50:27.775403Z","iopub.status.idle":"2022-05-14T11:50:27.876617Z","shell.execute_reply.started":"2022-05-14T11:50:27.775368Z","shell.execute_reply":"2022-05-14T11:50:27.875374Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"annotations = sorted(glob('/content/LungsTumorDetection/dataset/Train_Annotations/*.xml'))\n\ndf = []\ncnt = 0\nfor file in annotations:\n  prev_filename = file.split('/')[-1].split('.')[0] + '.jpg'\n  filename = str(cnt) + '.jpg'\n  row = []\n  parsedXML = ET.parse(file)\n  for node in parsedXML.getroot().iter('object'):\n    if node.find('name').text == \"STAS\" : blood_cells = \"stas\"\n    else : blood_cells = node.find('name').text\n    xmin = int(node.find('bndbox/xmin').text)\n    xmax = int(node.find('bndbox/xmax').text)\n    ymin = int(node.find('bndbox/ymin').text)\n    ymax = int(node.find('bndbox/ymax').text)\n\n    row = [prev_filename, filename, blood_cells, xmin, xmax, ymin, ymax]\n    df.append(row)\n  cnt += 1\n\ndata = pd.DataFrame(df, columns=['prev_filename', 'filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax'])\n\ndata[['prev_filename','filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax']].to_csv('/content/blood_cell_detection.csv', index=False)\n","metadata":{"id":"4_8R_DIIiQEY","execution":{"iopub.status.busy":"2022-05-14T11:51:18.987238Z","iopub.execute_input":"2022-05-14T11:51:18.988005Z","iopub.status.idle":"2022-05-14T11:51:19.153794Z","shell.execute_reply.started":"2022-05-14T11:51:18.987967Z","shell.execute_reply":"2022-05-14T11:51:19.153121Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Processing data as per the YOLO_V5 format","metadata":{"id":"_6cRsoE6VRAD"}},{"cell_type":"markdown","source":"**DATAFRAME STRUCTURE**\n\n- filename : contains the name of the image\n- cell_type: denotes the type of the cell\n- xmin: x-coordinate of the bottom left part of the image\n- xmax: x-coordinate of the top right part of the image\n- ymin: y-coordinate of the bottom left part of the image\n- ymax: y-coordinate of the top right part of the image\n- labels : Encoded cell-type **(Yolo - label input-1)**\n- width : width of that bbox\n- height : height of that bbox\n- x_center : bbox center (x-axis)\n-\ty_center : bbox center (y-axis)\n-\tx_center_norm\t: x_center normalized (0-1) **(Yolo - label input-2)**\n-\ty_center_norm : y_center normalized (0-1) **(Yolo - label input-3)**\n- width_norm : width normalized (0-1) **(Yolo - label input-4)**\n-\theight_norm : height normalized (0-1) **(Yolo - label input-5)**","metadata":{"id":"Onr1Vqm4x4qz"}},{"cell_type":"code","source":"img_width = 1716\nimg_height = 942\n\ndef width(df):\n  return int(df.xmax - df.xmin)\ndef height(df):\n  return int(df.ymax - df.ymin)\ndef x_center(df):\n  return int(df.xmin + (df.width/2))\ndef y_center(df):\n  return int(df.ymin + (df.height/2))\ndef w_norm(df):\n  return df/img_width\ndef h_norm(df):\n  return df/img_height\n\ndf = pd.read_csv('/content/blood_cell_detection.csv')\n\nle = preprocessing.LabelEncoder()\nle.fit(df['cell_type'])\nprint(le.classes_)\nlabels = le.transform(df['cell_type'])\ndf['labels'] = labels\n\ndf['width'] = df.apply(width, axis=1)\ndf['height'] = df.apply(height, axis=1)\n\ndf['x_center'] = df.apply(x_center, axis=1)\ndf['y_center'] = df.apply(y_center, axis=1)\n\ndf['x_center_norm'] = df['x_center'].apply(w_norm)\ndf['width_norm'] = df['width'].apply(w_norm)\n\ndf['y_center_norm'] = df['y_center'].apply(h_norm)\ndf['height_norm'] = df['height'].apply(h_norm)\n\ndf.head(30)","metadata":{"id":"2rybfBj3mwBV","outputId":"54a58d36-4c49-4023-a701-90a6d17f302c","execution":{"iopub.status.busy":"2022-05-14T11:51:24.628084Z","iopub.execute_input":"2022-05-14T11:51:24.628716Z","iopub.status.idle":"2022-05-14T11:51:25.059994Z","shell.execute_reply.started":"2022-05-14T11:51:24.628674Z","shell.execute_reply":"2022-05-14T11:51:25.059190Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#@title SAMPLE PLOT - shape (480, 640, 3)\nfig = plt.figure()\nimport cv2\n#add axes to the image\nax = fig.add_axes([0,0,1,1])\n\n# read and plot the image\nimage = plt.imread('/content/LungsTumorDetection/dataset/Train_Images/00000000.jpg')\nplt.imshow(image)\n\n# iterating over the image for different objects\nfor _,row in df[df.filename == \"1.jpg\"].iterrows():\n    xmin = row.xmin\n    xmax = row.xmax\n    ymin = row.ymin\n    ymax = row.ymax\n    \n    width = xmax - xmin\n    height = ymax - ymin\n    \n    # assign different color to different classes of objects\n    if row.cell_type == 'stas':\n        edgecolor = 'r'\n        ax.annotate('stas', xy=(xmax-40,ymin+20))\n        \n    # add bounding boxes to the image\n    rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = 'none')\n    \n    ax.add_patch(rect)","metadata":{"id":"pk4xn6BJ4B6q","outputId":"1296c268-8dd7-40c0-ec7c-8fc04e302b3f","execution":{"iopub.status.busy":"2022-05-14T06:53:44.313033Z","iopub.execute_input":"2022-05-14T06:53:44.313701Z","iopub.status.idle":"2022-05-14T06:53:45.051749Z","shell.execute_reply.started":"2022-05-14T06:53:44.313665Z","shell.execute_reply":"2022-05-14T06:53:45.048783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting into training and validation datasets","metadata":{"id":"CLnE5tWOVaKM"}},{"cell_type":"code","source":"df_train, df_valid = model_selection.train_test_split(df, test_size=0.35, random_state=13, shuffle=True)\nprint(df_train.shape, df_valid.shape)","metadata":{"id":"gRrIQI7m8H5P","outputId":"fa0c407b-8604-425f-960e-36310b81e3cf","execution":{"iopub.status.busy":"2022-05-14T11:51:52.337264Z","iopub.execute_input":"2022-05-14T11:51:52.337945Z","iopub.status.idle":"2022-05-14T11:51:52.346671Z","shell.execute_reply.started":"2022-05-14T11:51:52.337899Z","shell.execute_reply":"2022-05-14T11:51:52.345924Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/content/bcc/')\nos.mkdir('/content/bcc/images/')\nos.mkdir('/content/bcc/images/train/')\nos.mkdir('/content/bcc/images/valid/')\n\nos.mkdir('/content/bcc/labels/')\nos.mkdir('/content/bcc/labels/train/')\nos.mkdir('/content/bcc/labels/valid/')","metadata":{"id":"zO6iT6rQ-2f3","execution":{"iopub.status.busy":"2022-05-14T11:51:29.553150Z","iopub.execute_input":"2022-05-14T11:51:29.553593Z","iopub.status.idle":"2022-05-14T11:51:29.561522Z","shell.execute_reply.started":"2022-05-14T11:51:29.553549Z","shell.execute_reply":"2022-05-14T11:51:29.560842Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Data segregation and moving to it's corresponding folders\n- BCC\n  - Images\n    - Train (364 images [.jpg files])\n    - Valid (270 images [.jpg files])\n  - Labels\n    - Train (364 labels [.txt files])\n    - Valid (270 labels [.txt files])\n","metadata":{"id":"bmsqg2dYACVr"}},{"cell_type":"markdown","source":"**STRUCTURE OF .txt FILE**\n\n- One row per object\n- Each row is class x_center y_center width height format.\n- Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes  are in pixels, divide x_center and width by image width, and y_center and height by image height.\n- Class numbers are zero-indexed (start from 0).\n","metadata":{"id":"2IACNN0QxC4s"}},{"cell_type":"markdown","source":"<img src=\"https://github.com/bala-codes/Yolo-v5_Object_Detection_Blood_Cell_Count_and_Detection/blob/master/imgs/label_txt.PNG?raw=true\" width=\"50%\">\n","metadata":{"id":"_VgUi-pQ0BZo"}},{"cell_type":"code","source":"def segregate_data(df, img_path, label_path, train_img_path, train_label_path):\n  filenames = []\n  for filename in df.filename:\n    filenames.append(filename)\n  filenames = set(filenames)\n  \n  for filename in filenames:\n    yolo_list = []\n\n    for _,row in df[df.filename == filename].iterrows():\n      yolo_list.append([row.labels, row.x_center_norm, row.y_center_norm, row.width_norm, row.height_norm])\n\n    yolo_list = np.array(yolo_list)\n    txt_filename = os.path.join(train_label_path,str(row.prev_filename.split('.')[0])+\".txt\")\n    # Save the .img & .txt files to the corresponding train and validation folders\n    np.savetxt(txt_filename, yolo_list, fmt=[\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"])\n    shutil.copyfile(os.path.join(img_path,row.prev_filename), os.path.join(train_img_path,row.prev_filename))","metadata":{"id":"Bo21M14uF25h","execution":{"iopub.status.busy":"2022-05-14T11:51:33.580166Z","iopub.execute_input":"2022-05-14T11:51:33.580877Z","iopub.status.idle":"2022-05-14T11:51:33.589075Z","shell.execute_reply.started":"2022-05-14T11:51:33.580839Z","shell.execute_reply":"2022-05-14T11:51:33.587749Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"%%time\nsrc_img_path = \"/content/LungsTumorDetection/dataset/Train_Images/\"\nsrc_label_path = \"/content/LungsTumorDetection/dataset/Train_Annotations/\"\n\ntrain_img_path = \"/content/bcc/images/train\"\ntrain_label_path = \"/content/bcc/labels/train\"\n\nvalid_img_path = \"/content/bcc/images/valid\"\nvalid_label_path = \"/content/bcc/labels/valid\"\n\nsegregate_data(df_train, src_img_path, src_label_path, train_img_path, train_label_path)\nsegregate_data(df_valid, src_img_path, src_label_path, valid_img_path, valid_label_path)","metadata":{"id":"4uy4rLGYSBd7","outputId":"97022ef3-1424-4877-c096-6bc3390a9c7e","execution":{"iopub.status.busy":"2022-05-14T11:51:56.899736Z","iopub.execute_input":"2022-05-14T11:51:56.900359Z","iopub.status.idle":"2022-05-14T11:51:59.602528Z","shell.execute_reply.started":"2022-05-14T11:51:56.900299Z","shell.execute_reply":"2022-05-14T11:51:59.600983Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"try:\n  shutil.rmtree('/content/bcc/images/train/.ipynb_checkpoints')\nexcept FileNotFoundError:\n  pass\n\ntry:\n  shutil.rmtree('/content/bcc/images/valid/.ipynb_checkpoints')\nexcept FileNotFoundError:\n  pass\n\ntry:\n  shutil.rmtree('/content/bcc/labels/train/.ipynb_checkpoints')\nexcept FileNotFoundError:\n  pass\n\ntry:\n  shutil.rmtree('/content/bcc/labels/valid/.ipynb_checkpoints')\nexcept FileNotFoundError:\n  pass\n\nprint(\"No. of Training images\", len(os.listdir('/content/bcc/images/train')))\nprint(\"No. of Training labels\", len(os.listdir('/content/bcc/labels/train')))\n\nprint(\"No. of valid images\", len(os.listdir('/content/bcc/images/valid')))\nprint(\"No. of valid labels\", len(os.listdir('/content/bcc/labels/valid')))","metadata":{"id":"LDv31-CdS_nt","outputId":"2af11fcd-09b2-4e02-8fd2-ecc91028bfdf","execution":{"iopub.status.busy":"2022-05-14T11:52:01.784115Z","iopub.execute_input":"2022-05-14T11:52:01.784416Z","iopub.status.idle":"2022-05-14T11:52:01.801825Z","shell.execute_reply.started":"2022-05-14T11:52:01.784386Z","shell.execute_reply":"2022-05-14T11:52:01.800995Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# **END OF DATA PRE-PROCESSING**","metadata":{"id":"V2uPhrQCU6vT"}},{"cell_type":"markdown","source":"#**YOLO V5 STARTS**","metadata":{"id":"gjHmEIfmWNms"}},{"cell_type":"code","source":"!mkdir -p '/content/drive/My Drive/Machine Learning Projects/YOLO/'\n!cp -r '/content/bcc' '/content/drive/My Drive/Machine Learning Projects/YOLO/'","metadata":{"id":"05kiA297y2s3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cloning from the yolo v5 repo.\nMore can be found at here : [yolo](https://github.com/ultralytics/yolov5)","metadata":{"id":"lcA59GtHeCrd"}},{"cell_type":"code","source":"!git clone  'https://github.com/ultralytics/yolov5.git'","metadata":{"id":"YnhcNiuTGAK7","outputId":"364ce152-3164-4812-8030-2cf5a3427e9c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -qr '/content/LungsTumorDetection/yolov5/requirements.txt'  # install dependencies","metadata":{"id":"A4i0BpZIbyTz","outputId":"3f8bceb5-55b9-45c7-aaf2-c10c139987bf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# WE SHOULD CREATE A .yaml FILE AND THEN PLACE IT INSIDE THE yolov5 FOLDER","metadata":{"id":"KUsMKPtGeUcv"}},{"cell_type":"markdown","source":"#**Contents of YAML file**\n\ntrain: /content/bcc/images/train                    \nval: /content/bcc/images/valid\n\nnc: 3\n\nnames: ['Platelets', 'RBC', 'WBC']\n","metadata":{"id":"bqymagYif3Us"}},{"cell_type":"markdown","source":"<img src=\"https://github.com/bala-codes/Yolo-v5_Object_Detection_Blood_Cell_Count_and_Detection/blob/master/imgs/bcc_yaml.PNG?raw=true\" width=\"50%\">\n\n","metadata":{"id":"JNUfz-i21pVU"}},{"cell_type":"code","source":"!echo -e 'train: /content/bcc/images/train\\nval: /content/bcc/images/valid\\n\\nnc: 1\\nnames: ['stas']' >> bcc.yaml\n!cat 'bcc.yaml'","metadata":{"id":"IgIO3balXB-B","outputId":"eed4768f-a50a-420f-a24e-b7143c87f5e1","execution":{"iopub.status.busy":"2022-05-14T06:58:58.050512Z","iopub.execute_input":"2022-05-14T06:58:58.050809Z","iopub.status.idle":"2022-05-14T06:58:59.374195Z","shell.execute_reply.started":"2022-05-14T06:58:58.050763Z","shell.execute_reply":"2022-05-14T06:58:59.373381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.copyfile('/content/bcc.yaml', '/content/yolov5/bcc.yaml')","metadata":{"id":"31-z05sIcMcv","outputId":"3a83579a-383a-494a-c387-6f5da83b482c","execution":{"iopub.status.busy":"2022-05-14T06:59:01.398443Z","iopub.execute_input":"2022-05-14T06:59:01.399284Z","iopub.status.idle":"2022-05-14T06:59:01.454976Z","shell.execute_reply.started":"2022-05-14T06:59:01.399244Z","shell.execute_reply":"2022-05-14T06:59:01.453843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Also edit the number of classes (nc) in the ./models/*.yaml file**\n\nChoose the yolo model of your choice, here I chose yolov5s.yaml (yolo - small)\n","metadata":{"id":"7gUcPKfsDlEQ"}},{"cell_type":"code","source":"!sed -i 's/nc: 80/nc: 1/g' ./LungsTumorDetection/yolov5/models/yolov5m.yaml","metadata":{"id":"0cXuPZjRhg3o","execution":{"iopub.status.busy":"2022-05-14T11:52:13.058052Z","iopub.execute_input":"2022-05-14T11:52:13.058331Z","iopub.status.idle":"2022-05-14T11:52:13.779158Z","shell.execute_reply.started":"2022-05-14T11:52:13.058285Z","shell.execute_reply":"2022-05-14T11:52:13.778207Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/600/1*hCE5VwKkqHlZW466umYTTA.png\">","metadata":{"id":"zL2G0EG1EJQs"}},{"cell_type":"markdown","source":"# Training command","metadata":{"id":"g_4-F3I2gVIN"}},{"cell_type":"markdown","source":"**Training Parameters**\n\n!python \n- <'location of train.py file'> \n- --img <'width of image'>\n- --batch <'batch size'>\n- --epochs <'no of epochs'>\n- --data <'location of the .yaml file'>\n- --cfg <'Which yolo configuration you want'>(yolov5s/yolov5m/yolov5l/yolov5x).yaml | (small, medium, large, xlarge)\n- --name <'Name of the best model after training'>","metadata":{"id":"127Pw1oS1zzY"}},{"cell_type":"markdown","source":"**METRICS FROM TRAINING PROCESS**\n\n**No.of classes, No.of images, No.of targets, Precision (P), Recall (R), mean Average Precision (map)**\n- Class | Images | Targets | P | R | mAP@.5 | mAP@.5:.95: |\n- all   | 270    |     489 |    0.0899 |       0.827 |      0.0879 |      0.0551","metadata":{"id":"Ztjc7_wS5z2J"}},{"cell_type":"code","source":"!pwd","metadata":{"id":"SY-Mw2bJjZto","outputId":"e9354b11-271c-4c52-d40c-d6628e96a5f7","execution":{"iopub.status.busy":"2022-05-14T11:52:18.564503Z","iopub.execute_input":"2022-05-14T11:52:18.564776Z","iopub.status.idle":"2022-05-14T11:52:19.239550Z","shell.execute_reply.started":"2022-05-14T11:52:18.564747Z","shell.execute_reply":"2022-05-14T11:52:19.238666Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"Q_zEQzDtpX1S","outputId":"852f616d-7e78-44f7-d0c1-e38e34048b61","execution":{"iopub.status.busy":"2022-05-14T11:52:21.020443Z","iopub.execute_input":"2022-05-14T11:52:21.020727Z","iopub.status.idle":"2022-05-14T11:52:21.719479Z","shell.execute_reply.started":"2022-05-14T11:52:21.020699Z","shell.execute_reply":"2022-05-14T11:52:21.718511Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"/content/LungsTumorDetection/yolov5\")","metadata":{"id":"ohzsJt9zwYrQ","execution":{"iopub.status.busy":"2022-05-14T11:52:28.045805Z","iopub.execute_input":"2022-05-14T11:52:28.046177Z","iopub.status.idle":"2022-05-14T11:52:28.052556Z","shell.execute_reply.started":"2022-05-14T11:52:28.046135Z","shell.execute_reply":"2022-05-14T11:52:28.051693Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"%%time\n\n!python train.py --img 640 --batch 40 --epochs 100 --data bcc.yaml --cfg models/yolov5m.yaml --name BCCM","metadata":{"id":"k3Tc61Qzd4lY","outputId":"24d66ae1-e068-41fd-ed35-9a08958d7d4e","execution":{"iopub.status.busy":"2022-05-14T11:52:34.485637Z","iopub.execute_input":"2022-05-14T11:52:34.485905Z","iopub.status.idle":"2022-05-14T14:47:15.300891Z","shell.execute_reply.started":"2022-05-14T11:52:34.485877Z","shell.execute_reply":"2022-05-14T14:47:15.300017Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"wcAWrYQkQ4zr"}},{"cell_type":"code","source":"print(os.listdir(\"/content/LungsTumorDetection/dataset\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:12:52.266982Z","iopub.execute_input":"2022-05-14T15:12:52.267256Z","iopub.status.idle":"2022-05-14T15:12:52.276704Z","shell.execute_reply.started":"2022-05-14T15:12:52.267224Z","shell.execute_reply":"2022-05-14T15:12:52.275050Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"/content/LungsTumorDetection/dataset\")","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:12:47.072835Z","iopub.execute_input":"2022-05-14T15:12:47.073102Z","iopub.status.idle":"2022-05-14T15:12:47.078920Z","shell.execute_reply.started":"2022-05-14T15:12:47.073073Z","shell.execute_reply":"2022-05-14T15:12:47.078030Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"!zip -r /evrything.zip content","metadata":{"id":"PQ8mjRtX8ajw","outputId":"217457cc-e4f4-4e11-e8c3-35c90bd9ac89","execution":{"iopub.status.busy":"2022-05-14T15:48:44.334032Z","iopub.execute_input":"2022-05-14T15:48:44.334670Z","iopub.status.idle":"2022-05-14T15:48:45.098822Z","shell.execute_reply.started":"2022-05-14T15:48:44.334629Z","shell.execute_reply":"2022-05-14T15:48:45.097804Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:55:42.049838Z","iopub.execute_input":"2022-05-14T15:55:42.050124Z","iopub.status.idle":"2022-05-14T15:55:42.756728Z","shell.execute_reply.started":"2022-05-14T15:55:42.050093Z","shell.execute_reply":"2022-05-14T15:55:42.755865Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"os.chdir('/kaggle/wo')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:55:39.645816Z","iopub.execute_input":"2022-05-14T15:55:39.646089Z","iopub.status.idle":"2022-05-14T15:55:39.652653Z","shell.execute_reply.started":"2022-05-14T15:55:39.646060Z","shell.execute_reply":"2022-05-14T15:55:39.651938Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(r'evrything.zip')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:48:05.483467Z","iopub.execute_input":"2022-05-14T15:48:05.483846Z","iopub.status.idle":"2022-05-14T15:48:05.493399Z","shell.execute_reply.started":"2022-05-14T15:48:05.483800Z","shell.execute_reply":"2022-05-14T15:48:05.492513Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# Start tensorboard (optional)\n%load_ext tensorboard\n%tensorboard --logdir runs/","metadata":{"id":"i7upZcFvhWhN","outputId":"15e8d2bd-445f-4eae-ceb7-f4466b6b0366"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**INFERENCE**","metadata":{"id":"DJYN1lb_uV-T"}},{"cell_type":"code","source":"#Optimizer stripped from runs/exp2_BCCM/weights/last_BCCM.pt, 14.8MB\n#Optimizer stripped from runs/exp2_BCCM/weights/best_BCCM.pt, 14.8MB","metadata":{"id":"FHnXEx4subZ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BATCH PREDICTION\n- Results saved to inference/output\n","metadata":{"id":"obKZFwYHvg6a"}},{"cell_type":"markdown","source":"**Inference Parameters**\n\n!python \n- <'location of detect.py file'> \n- --source <'location of image/ folder to predict'>\n- --weight <'location of the saved best weights'>\n- --output <'location of output files after prediction'>","metadata":{"id":"jtCUnoyr7h8y"}},{"cell_type":"code","source":"os.mkdir('/content/inference')\nos.mkdir('/content/inference/output')","metadata":{"id":"6zpDOMr-igtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"id":"OfUNrZol-cCR","outputId":"dc4d1a5e-f0e7-435e-e850-d1ac00db7b81","execution":{"iopub.status.busy":"2022-05-14T14:53:16.907383Z","iopub.execute_input":"2022-05-14T14:53:16.907660Z","iopub.status.idle":"2022-05-14T14:53:17.562491Z","shell.execute_reply.started":"2022-05-14T14:53:16.907633Z","shell.execute_reply":"2022-05-14T14:53:17.561648Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"/content/output\")","metadata":{"id":"PwGRcHKi-Bfh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport json\n\ndef get_filename(im):\n  a = im.filename\n  b = a.split('/')[3]\n  return b","metadata":{"id":"TNAR4SW8dY6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python /content/yolov5/detect.py --source /content/valid --weights '/content/yolov5/runs/train/BCCM4/weights/best.pt'","metadata":{"id":"PoDLzE4xu_Bo","outputId":"ff21907f-531e-49df-ae8d-14c142a7aecb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disp_images = glob('/content/inference/output/*')\nfig=plt.figure(figsize=(20, 28))\ncolumns = 3\nrows = 5\nfor i in range(1, columns*rows +1):\n    img = np.random.choice(disp_images)\n    img = plt.imread(img)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","metadata":{"id":"1UFERGRGwOEQ","outputId":"cd0ebebc-ac6a-4b27-e681-58d91fe85362"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SINGLE IMAGE PREDICTIONS\n","metadata":{"id":"wrXZ10ikvnDB"}},{"cell_type":"code","source":"output = !python /content/yolov5/detect.py --source /content/valid/Public_00000000.jpg --weights '/content/yolov5/runs/train/BCCM4/weights/best.pt'\nprint(output)","metadata":{"id":"RuIiMYKdvRi1","outputId":"cb372015-ddeb-4f49-b69b-26b61a7d6fb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"id":"H9MtUM2Ef2Ff","outputId":"15fb3edc-c567-4af9-99a8-1cbfc92c2d2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport torch\nfrom PIL import Image\nimport json\n\ndef get_filename(im):\n  a = im.filename\n  b = a.split('/')[3]\n  return b\n\n# Model\nmodel = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/LungsTumorDetection/yolov5/weights/best.pt')  # local model\ndict_x = {}\n\n# Images\nfor im_list in list(glob('/content/LungsTumorDetection/dataset/Public_Image/*.jpg')):\n  im = Image.open(im_list)  # PIL image\n  # Inference\n  results = model(im, size=1920)  # includes NMS\n\n# # Results\n# results.print()  \n# results.save()  # or .show()\n# results.xyxy[0]  # im1 predictions (tensor)\n# print(results.pandas().xyxy[0].shape)  # im1 predictions (pandas)\n\n  list_x = []\n  signal = 0\n  for i in results.pandas().xyxy[0].values:\n    if (i[4]>=0.05): \n      temp_value = float(\"{0:.5f}\".format(i[4]))\n      templist_x=[int(j) for j in i[0:4]]\n      templist_x.append(temp_value)\n      list_x.append(templist_x)\n  dict_x.update({get_filename(im):list_x})\n  print(list_x)\n\nprint(dict_x)\nprint(len(dict_x))\nwith open('result.json', 'w', encoding='utf-8') as f:\n    json.dump(dict_x, f, ensure_ascii=False)","metadata":{"id":"7x0JzWTJMmvl","outputId":"bd14f253-4d17-4f98-e50a-b37996592ce6","execution":{"iopub.status.busy":"2022-05-14T15:46:05.853666Z","iopub.execute_input":"2022-05-14T15:46:05.854007Z","iopub.status.idle":"2022-05-14T15:46:15.190566Z","shell.execute_reply.started":"2022-05-14T15:46:05.853973Z","shell.execute_reply":"2022-05-14T15:46:15.189673Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"AfLPw_aDmyv7","outputId":"55747f16-20c4-4bad-d5b8-d3d0099dc12f","execution":{"iopub.status.busy":"2022-05-14T15:35:08.701535Z","iopub.execute_input":"2022-05-14T15:35:08.702382Z","iopub.status.idle":"2022-05-14T15:35:08.706029Z","shell.execute_reply.started":"2022-05-14T15:35:08.702333Z","shell.execute_reply":"2022-05-14T15:35:08.705223Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"for i in output:\n  print(i)","metadata":{"id":"8ttZSrGtITYi","outputId":"b136e2a2-e9fa-4c32-c1e3-d059d4b29f77"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# You need these files, if you wish to move the model to production","metadata":{"id":"-1ZarG561ak5"}},{"cell_type":"markdown","source":"## Files","metadata":{"id":"AxI5iupx_jd1"}},{"cell_type":"code","source":"shutil.copyfile('/content/yolov5/detect.py', '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/detect.py')\nshutil.copyfile('/content/yolov5/requirements.txt', '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/requirements.txt')\nshutil.copyfile('/content/runs/exp2_BCCM/weights/best_BCCM.pt', '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/best_BCCM.pt')\n\n","metadata":{"id":"NSAegF-48fHj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"Kd-aarpL_lB1"}},{"cell_type":"code","source":"!cp -r '/content/yolov5/models' '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/'\n!cp -r '/content/yolov5/utils' '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/'\n","metadata":{"id":"I1Gup2m3vv_M"},"execution_count":null,"outputs":[]}]}